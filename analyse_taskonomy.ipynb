{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import classes\n",
    "\n",
    "# modified visualpriors library\n",
    "from transforms import VisualPriorRepresentation, VisualPriorPredictedLabel\n",
    "from taskonomy_network import TaskonomyEncoder, TaskonomyDecoder\n",
    "\n",
    "import os\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torchsummary\n",
    "\n",
    "from PIL import Image\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.io import savemat\n",
    "\n",
    "import torch.utils.model_zoo # required to load nets\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch import nn\n",
    "import torchvision.models\n",
    "from torchvision.models.feature_extraction import get_graph_node_names, create_feature_extractor\n",
    "\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis for all taskonomy models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_taskonomy_encoder_integration_analysis(task, places_images):\n",
    "    VisualPriorRepresentation._load_unloaded_nets([task])\n",
    "    net = VisualPriorRepresentation.feature_task_to_net[task]\n",
    "\n",
    "    _, eval_nodes = get_graph_node_names(net)\n",
    "    return_nodes = { node:node for node in eval_nodes if \"conv\" in node or 'fc' in node}\n",
    "    net_tweaked = create_feature_extractor(net, return_nodes=return_nodes)\n",
    "\n",
    "    integration_calc = classes.IntegrationCalculator(net_tweaked, return_nodes)\n",
    "    return classes.calculate_dataset_integration(places_images, integration_calc)\n",
    "\n",
    "#VisualPrior.viable_feature_tasks\n",
    "tasks = ('autoencoding','depth_euclidean','jigsaw','reshading',\n",
    "         'colorization', 'edge_occlusion','keypoints2d','room_layout',\n",
    "         'curvature','edge_texture','keypoints3d','segment_unsup2d',\n",
    "         'class_object','egomotion','nonfixated_pose','segment_unsup25d',\n",
    "         'class_scene','fixated_pose','normal','segment_semantic',\n",
    "         'denoising','inpainting','point_matching','vanishing_point')\n",
    "\n",
    "places_images = classes.ImageDataset('./data/stimuli_places1', beauty_ratings_path='./behavior/ratings_study1.csv')\n",
    "\n",
    "mdict = {}\n",
    "for task in tasks:\n",
    "    task_result = run_taskonomy_encoder_integration_analysis(task, places_images)\n",
    "    task_result.to_csv(os.path.join('results', task, task + '.csv'))\n",
    "    #mdict[task] = run_taskonomy_encoder_integration_analysis(task, places_images)\n",
    "\n",
    "\n",
    "\n",
    "#savemat(\"taskonomy_integration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "\n",
    "X = StandardScaler().fit_transform(result)\n",
    "y = StandardScaler().fit_transform(pd.DataFrame(places_images.beauty_ratings))\n",
    "X.shape, y.shape\n",
    "loo, predictions = LeaveOneOut(), []\n",
    "\n",
    "for train_idx, predict_idx in loo.split(X):\n",
    "    glm = LinearRegression().fit(X[train_idx], y[train_idx])\n",
    "    predictions.append(glm.predict(X[predict_idx]).item())\n",
    "\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "pearsonr(predictions, places_images.beauty_ratings)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
