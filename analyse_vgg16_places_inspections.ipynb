{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import classes\n",
    "import torchsummary\n",
    "\n",
    "from scipy.io import savemat, loadmat\n",
    "\n",
    "import torch\n",
    "import torchvision.io\n",
    "from torch import nn\n",
    "from torchvision.models.feature_extraction import get_graph_node_names, create_feature_extractor\n",
    "\n",
    "#import torch.utils.model_zoo # required to load nets\n",
    "#import torchvision.transforms.functional as TF\n",
    "#import torchvision.models\n",
    "\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTo check that the implementation of the code is correct, the analysis of vgg16_playes net is repeated here,\\nwhich should reproduce the same results as in the matlab implementation.\\n\\nThe boilerplate code for this is a bit different, since the vgg16_places model is imported from a different source\\nand in a different format than the Taskonomy models.\\n\\nAs soon as the model is brought into the right format, the analysis steps are the same in principle.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "To check that the implementation of the code is correct, the analysis of vgg16_playes net is repeated here,\n",
    "which should reproduce the same results as in the matlab implementation.\n",
    "\n",
    "The boilerplate code for this is a bit different, since the vgg16_places model is imported from a different source\n",
    "and in a different format than the Taskonomy models.\n",
    "\n",
    "As soon as the model is brought into the right format, the analysis steps are the same in principle.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare VGG16_places365"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import parameters into replicated architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_places = nn.Sequential(\n",
    "    collections.OrderedDict(\n",
    "        [\n",
    "            ('conv1_1', nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1)),\n",
    "            ('ReLU1_1', nn.ReLU()),\n",
    "            ('conv1_2', nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)),\n",
    "            ('ReLU1_2',nn.ReLU()),\n",
    "            ('MaxPool1', nn.MaxPool2d(kernel_size=2, stride=2,padding=0)),\n",
    "            ('conv2_1',nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)),\n",
    "            ('ReLU2_1',nn.ReLU()),\n",
    "            ('conv2_2',nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)),\n",
    "            ('ReLU2_2',nn.ReLU()),\n",
    "            ('MaxPool2', nn.MaxPool2d(kernel_size=2, stride=2,padding=0)),\n",
    "            ('conv3_1', nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)),\n",
    "            ('ReLU3_1',nn.ReLU()),\n",
    "            ('conv3_2', nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1)),\n",
    "            ('ReLU3_2',nn.ReLU()),\n",
    "            ('conv3_3', nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1)),\n",
    "            ('ReLU3_3',nn.ReLU()),\n",
    "            ('MaxPool3', nn.MaxPool2d(kernel_size=2, stride=2,padding=0)),\n",
    "            ('conv4_1', nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1)),\n",
    "            ('ReLU4_1',nn.ReLU()),\n",
    "            ('conv4_2', nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)),\n",
    "            ('ReLU4_2',nn.ReLU()),\n",
    "            ('conv4_3', nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)),\n",
    "            ('ReLU4_3',nn.ReLU()),\n",
    "            ('MaxPool4', nn.MaxPool2d(kernel_size=2, stride=2,padding=0)),\n",
    "            ('conv5_1', nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)),\n",
    "            ('ReLU5_1',nn.ReLU()),\n",
    "            ('conv5_2', nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)),\n",
    "            ('ReLU5_2',nn.ReLU()),\n",
    "            ('conv5_3', nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)),\n",
    "            ('ReLU5_3',nn.ReLU()),\n",
    "            ('MaxPool5', nn.MaxPool2d(kernel_size=2, stride=2,padding=0)),\n",
    "            ('Flatten6', nn.Flatten()),\n",
    "            ('fc6', nn.Linear(in_features=25088, out_features=4096)),\n",
    "            ('ReLU6',nn.ReLU()),\n",
    "            ('fc7', nn.Linear(in_features=4096, out_features=4096)),\n",
    "            ('ReLU7',nn.ReLU()),\n",
    "            ('fc8a', nn.Linear(in_features=4096, out_features=365)),\n",
    "            ('Softmax8a', nn.Softmax(dim=-1))\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16_places_statedict = torch.load('vgg16_places365.caffemodel.pt')\n",
    "vgg16_places.load_state_dict(vgg16_places_statedict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build feature(activations) extractor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, eval_nodes = get_graph_node_names(vgg16_places)\n",
    "#for node in eval_nodes:\n",
    "#    print(node, end='   ')\n",
    "\n",
    "return_nodes = { node:node for node in eval_nodes if \"conv\" in node or 'fc' in node}\n",
    "\n",
    "vgg16_places_fe = create_feature_extractor(vgg16_places, return_nodes=return_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "              ReLU-2         [-1, 64, 224, 224]               0\n",
      "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
      "              ReLU-4         [-1, 64, 224, 224]               0\n",
      "         MaxPool2d-5         [-1, 64, 112, 112]               0\n",
      "            Conv2d-6        [-1, 128, 112, 112]          73,856\n",
      "              ReLU-7        [-1, 128, 112, 112]               0\n",
      "            Conv2d-8        [-1, 128, 112, 112]         147,584\n",
      "              ReLU-9        [-1, 128, 112, 112]               0\n",
      "        MaxPool2d-10          [-1, 128, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]         295,168\n",
      "             ReLU-12          [-1, 256, 56, 56]               0\n",
      "           Conv2d-13          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-14          [-1, 256, 56, 56]               0\n",
      "           Conv2d-15          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-16          [-1, 256, 56, 56]               0\n",
      "        MaxPool2d-17          [-1, 256, 28, 28]               0\n",
      "           Conv2d-18          [-1, 512, 28, 28]       1,180,160\n",
      "             ReLU-19          [-1, 512, 28, 28]               0\n",
      "           Conv2d-20          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-21          [-1, 512, 28, 28]               0\n",
      "           Conv2d-22          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-23          [-1, 512, 28, 28]               0\n",
      "        MaxPool2d-24          [-1, 512, 14, 14]               0\n",
      "           Conv2d-25          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-26          [-1, 512, 14, 14]               0\n",
      "           Conv2d-27          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-28          [-1, 512, 14, 14]               0\n",
      "           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-30          [-1, 512, 14, 14]               0\n",
      "        MaxPool2d-31            [-1, 512, 7, 7]               0\n",
      "          Flatten-32                [-1, 25088]               0\n",
      "           Linear-33                 [-1, 4096]     102,764,544\n",
      "             ReLU-34                 [-1, 4096]               0\n",
      "           Linear-35                 [-1, 4096]      16,781,312\n",
      "             ReLU-36                 [-1, 4096]               0\n",
      "           Linear-37                  [-1, 365]       1,495,405\n",
      "================================================================\n",
      "Total params: 135,755,949\n",
      "Trainable params: 135,755,949\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 218.71\n",
      "Params size (MB): 517.87\n",
      "Estimated Total Size (MB): 737.16\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(vgg16_places_fe, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integration & beauty, compare to Taskonomy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './behavior/ratings_study1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m places_images \u001b[38;5;241m=\u001b[39m \u001b[43mclasses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImageDatasetMatfiles\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/stimuli_places1_resized\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeauty_ratings_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./behavior/ratings_study1.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m integration_calc \u001b[38;5;241m=\u001b[39m classes\u001b[38;5;241m.\u001b[39mIntegrationCalculatorVGG16Matfiles(vgg16_places_fe, return_nodes)\n\u001b[1;32m      3\u001b[0m results_vgg16 \u001b[38;5;241m=\u001b[39m classes\u001b[38;5;241m.\u001b[39mImageDatasetMatfiles\u001b[38;5;241m.\u001b[39mcalculate_dataset_integration_Matfiles(places_images, integration_calc)\n",
      "File \u001b[0;32m~/Documents/Thesis/Taskonomy Integration/classes.py:157\u001b[0m, in \u001b[0;36mImageDatasetMatfiles.__init__\u001b[0;34m(self, img_dir, beauty_ratings_path)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dir_img_list)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m beauty_ratings_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeauty_ratings \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeauty_ratings_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/PytorchEnv/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/PytorchEnv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:678\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    663\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    664\u001b[0m     dialect,\n\u001b[1;32m    665\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    674\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    675\u001b[0m )\n\u001b[1;32m    676\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/PytorchEnv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/envs/PytorchEnv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:932\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    929\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    931\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/PytorchEnv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1216\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1212\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1227\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/envs/PytorchEnv/lib/python3.8/site-packages/pandas/io/common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 786\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    793\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './behavior/ratings_study1.csv'"
     ]
    }
   ],
   "source": [
    "places_images = classes.ImageDatasetMatfiles('./data/stimuli_places1_resized', beauty_ratings_path='./behavior/ratings_study1.csv')\n",
    "integration_calc = classes.IntegrationCalculatorVGG16Matfiles(vgg16_places_fe, return_nodes)\n",
    "results_vgg16 = classes.ImageDatasetMatfiles.calculate_dataset_integration_Matfiles(places_images, integration_calc)\n",
    "results_vgg16.to_csv('./results/vgg16_places/vgg16_places_results.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_vgg16 = pd.read_csv('./results/vgg16_places/vgg16_places_results.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_autoencoding = pd.read_csv('./results/autoencoding/autoencoding.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlate integration and beauty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x73c6003253a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes.correlate_integration_beauty(results_vgg16, places_images.beauty_ratings).plot(ylim=(-.2,.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_autoencoding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m classes\u001b[38;5;241m.\u001b[39mcorrelate_integration_beauty(\u001b[43mresults_autoencoding\u001b[49m, places_images\u001b[38;5;241m.\u001b[39mbeauty_ratings)\u001b[38;5;241m.\u001b[39mplot(ylim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m.2\u001b[39m,\u001b[38;5;241m.8\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results_autoencoding' is not defined"
     ]
    }
   ],
   "source": [
    "classes.correlate_integration_beauty(results_autoencoding, places_images.beauty_ratings).plot(ylim=(-.2,.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conv1</th>\n",
       "      <th>conv1_1</th>\n",
       "      <th>conv2</th>\n",
       "      <th>conv2_1</th>\n",
       "      <th>conv3</th>\n",
       "      <th>conv3_1</th>\n",
       "      <th>conv3_2</th>\n",
       "      <th>conv4</th>\n",
       "      <th>conv4_1</th>\n",
       "      <th>conv4_2</th>\n",
       "      <th>conv5</th>\n",
       "      <th>conv5_1</th>\n",
       "      <th>conv5_2</th>\n",
       "      <th>fc6</th>\n",
       "      <th>fc7</th>\n",
       "      <th>fc8a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.983123</td>\n",
       "      <td>-0.972471</td>\n",
       "      <td>-0.969690</td>\n",
       "      <td>-0.932361</td>\n",
       "      <td>-0.870340</td>\n",
       "      <td>-0.867848</td>\n",
       "      <td>-0.861324</td>\n",
       "      <td>-0.792860</td>\n",
       "      <td>-0.836010</td>\n",
       "      <td>-0.784744</td>\n",
       "      <td>-0.770835</td>\n",
       "      <td>-0.837915</td>\n",
       "      <td>-0.801580</td>\n",
       "      <td>-0.912642</td>\n",
       "      <td>-0.904536</td>\n",
       "      <td>-0.849672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.988474</td>\n",
       "      <td>-0.970777</td>\n",
       "      <td>-0.970677</td>\n",
       "      <td>-0.946647</td>\n",
       "      <td>-0.920898</td>\n",
       "      <td>-0.911696</td>\n",
       "      <td>-0.896856</td>\n",
       "      <td>-0.846613</td>\n",
       "      <td>-0.840459</td>\n",
       "      <td>-0.799933</td>\n",
       "      <td>-0.826476</td>\n",
       "      <td>-0.891256</td>\n",
       "      <td>-0.900086</td>\n",
       "      <td>-0.964162</td>\n",
       "      <td>-0.961519</td>\n",
       "      <td>-0.962565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.989495</td>\n",
       "      <td>-0.973141</td>\n",
       "      <td>-0.974408</td>\n",
       "      <td>-0.953882</td>\n",
       "      <td>-0.930552</td>\n",
       "      <td>-0.923199</td>\n",
       "      <td>-0.912643</td>\n",
       "      <td>-0.869097</td>\n",
       "      <td>-0.878391</td>\n",
       "      <td>-0.830931</td>\n",
       "      <td>-0.818602</td>\n",
       "      <td>-0.889172</td>\n",
       "      <td>-0.871852</td>\n",
       "      <td>-0.951417</td>\n",
       "      <td>-0.935921</td>\n",
       "      <td>-0.919300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.989586</td>\n",
       "      <td>-0.980083</td>\n",
       "      <td>-0.977478</td>\n",
       "      <td>-0.946990</td>\n",
       "      <td>-0.907716</td>\n",
       "      <td>-0.904630</td>\n",
       "      <td>-0.890270</td>\n",
       "      <td>-0.855537</td>\n",
       "      <td>-0.864602</td>\n",
       "      <td>-0.815427</td>\n",
       "      <td>-0.821811</td>\n",
       "      <td>-0.884210</td>\n",
       "      <td>-0.901800</td>\n",
       "      <td>-0.961100</td>\n",
       "      <td>-0.958398</td>\n",
       "      <td>-0.965751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.991258</td>\n",
       "      <td>-0.981188</td>\n",
       "      <td>-0.978538</td>\n",
       "      <td>-0.949577</td>\n",
       "      <td>-0.909039</td>\n",
       "      <td>-0.907792</td>\n",
       "      <td>-0.890851</td>\n",
       "      <td>-0.865774</td>\n",
       "      <td>-0.892154</td>\n",
       "      <td>-0.851080</td>\n",
       "      <td>-0.847102</td>\n",
       "      <td>-0.883068</td>\n",
       "      <td>-0.875207</td>\n",
       "      <td>-0.959389</td>\n",
       "      <td>-0.953732</td>\n",
       "      <td>-0.941918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>-0.983311</td>\n",
       "      <td>-0.962983</td>\n",
       "      <td>-0.963242</td>\n",
       "      <td>-0.941431</td>\n",
       "      <td>-0.901636</td>\n",
       "      <td>-0.887660</td>\n",
       "      <td>-0.869910</td>\n",
       "      <td>-0.783837</td>\n",
       "      <td>-0.774626</td>\n",
       "      <td>-0.718336</td>\n",
       "      <td>-0.725431</td>\n",
       "      <td>-0.791481</td>\n",
       "      <td>-0.790926</td>\n",
       "      <td>-0.913020</td>\n",
       "      <td>-0.891236</td>\n",
       "      <td>-0.835036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>-0.986610</td>\n",
       "      <td>-0.972127</td>\n",
       "      <td>-0.971881</td>\n",
       "      <td>-0.945548</td>\n",
       "      <td>-0.913277</td>\n",
       "      <td>-0.908537</td>\n",
       "      <td>-0.895740</td>\n",
       "      <td>-0.879633</td>\n",
       "      <td>-0.882571</td>\n",
       "      <td>-0.847796</td>\n",
       "      <td>-0.875402</td>\n",
       "      <td>-0.908133</td>\n",
       "      <td>-0.921162</td>\n",
       "      <td>-0.973889</td>\n",
       "      <td>-0.973316</td>\n",
       "      <td>-0.976925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>-0.989653</td>\n",
       "      <td>-0.983949</td>\n",
       "      <td>-0.977510</td>\n",
       "      <td>-0.941544</td>\n",
       "      <td>-0.882314</td>\n",
       "      <td>-0.889077</td>\n",
       "      <td>-0.883545</td>\n",
       "      <td>-0.843965</td>\n",
       "      <td>-0.871419</td>\n",
       "      <td>-0.835822</td>\n",
       "      <td>-0.812478</td>\n",
       "      <td>-0.860232</td>\n",
       "      <td>-0.848119</td>\n",
       "      <td>-0.924650</td>\n",
       "      <td>-0.888101</td>\n",
       "      <td>-0.843361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>-0.990375</td>\n",
       "      <td>-0.972764</td>\n",
       "      <td>-0.980901</td>\n",
       "      <td>-0.960154</td>\n",
       "      <td>-0.939933</td>\n",
       "      <td>-0.937857</td>\n",
       "      <td>-0.932748</td>\n",
       "      <td>-0.895055</td>\n",
       "      <td>-0.914636</td>\n",
       "      <td>-0.876649</td>\n",
       "      <td>-0.894824</td>\n",
       "      <td>-0.943529</td>\n",
       "      <td>-0.931882</td>\n",
       "      <td>-0.975520</td>\n",
       "      <td>-0.972920</td>\n",
       "      <td>-0.968108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>-0.995635</td>\n",
       "      <td>-0.990272</td>\n",
       "      <td>-0.986379</td>\n",
       "      <td>-0.960376</td>\n",
       "      <td>-0.929502</td>\n",
       "      <td>-0.935153</td>\n",
       "      <td>-0.920638</td>\n",
       "      <td>-0.900751</td>\n",
       "      <td>-0.918813</td>\n",
       "      <td>-0.882179</td>\n",
       "      <td>-0.889934</td>\n",
       "      <td>-0.932338</td>\n",
       "      <td>-0.925461</td>\n",
       "      <td>-0.967022</td>\n",
       "      <td>-0.955408</td>\n",
       "      <td>-0.949287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows  16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        conv1   conv1_1     conv2   conv2_1     conv3   conv3_1   conv3_2  \\\n",
       "0   -0.983123 -0.972471 -0.969690 -0.932361 -0.870340 -0.867848 -0.861324   \n",
       "1   -0.988474 -0.970777 -0.970677 -0.946647 -0.920898 -0.911696 -0.896856   \n",
       "2   -0.989495 -0.973141 -0.974408 -0.953882 -0.930552 -0.923199 -0.912643   \n",
       "3   -0.989586 -0.980083 -0.977478 -0.946990 -0.907716 -0.904630 -0.890270   \n",
       "4   -0.991258 -0.981188 -0.978538 -0.949577 -0.909039 -0.907792 -0.890851   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "245 -0.983311 -0.962983 -0.963242 -0.941431 -0.901636 -0.887660 -0.869910   \n",
       "246 -0.986610 -0.972127 -0.971881 -0.945548 -0.913277 -0.908537 -0.895740   \n",
       "247 -0.989653 -0.983949 -0.977510 -0.941544 -0.882314 -0.889077 -0.883545   \n",
       "248 -0.990375 -0.972764 -0.980901 -0.960154 -0.939933 -0.937857 -0.932748   \n",
       "249 -0.995635 -0.990272 -0.986379 -0.960376 -0.929502 -0.935153 -0.920638   \n",
       "\n",
       "        conv4   conv4_1   conv4_2     conv5   conv5_1   conv5_2       fc6  \\\n",
       "0   -0.792860 -0.836010 -0.784744 -0.770835 -0.837915 -0.801580 -0.912642   \n",
       "1   -0.846613 -0.840459 -0.799933 -0.826476 -0.891256 -0.900086 -0.964162   \n",
       "2   -0.869097 -0.878391 -0.830931 -0.818602 -0.889172 -0.871852 -0.951417   \n",
       "3   -0.855537 -0.864602 -0.815427 -0.821811 -0.884210 -0.901800 -0.961100   \n",
       "4   -0.865774 -0.892154 -0.851080 -0.847102 -0.883068 -0.875207 -0.959389   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "245 -0.783837 -0.774626 -0.718336 -0.725431 -0.791481 -0.790926 -0.913020   \n",
       "246 -0.879633 -0.882571 -0.847796 -0.875402 -0.908133 -0.921162 -0.973889   \n",
       "247 -0.843965 -0.871419 -0.835822 -0.812478 -0.860232 -0.848119 -0.924650   \n",
       "248 -0.895055 -0.914636 -0.876649 -0.894824 -0.943529 -0.931882 -0.975520   \n",
       "249 -0.900751 -0.918813 -0.882179 -0.889934 -0.932338 -0.925461 -0.967022   \n",
       "\n",
       "          fc7      fc8a  \n",
       "0   -0.904536 -0.849672  \n",
       "1   -0.961519 -0.962565  \n",
       "2   -0.935921 -0.919300  \n",
       "3   -0.958398 -0.965751  \n",
       "4   -0.953732 -0.941918  \n",
       "..        ...       ...  \n",
       "245 -0.891236 -0.835036  \n",
       "246 -0.973316 -0.976925  \n",
       "247 -0.888101 -0.843361  \n",
       "248 -0.972920 -0.968108  \n",
       "249 -0.955408 -0.949287  \n",
       "\n",
       "[250 rows x 16 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      86.00\n",
       "1      70.76\n",
       "2      33.68\n",
       "3      35.84\n",
       "4      40.72\n",
       "       ...  \n",
       "245    60.76\n",
       "246    38.52\n",
       "247    65.24\n",
       "248    56.44\n",
       "249    62.48\n",
       "Length: 250, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "places_images.beauty_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect models (export data to matlab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = dict(vgg16_places.state_dict())\n",
    "savemat('../matlab analysis/PyVGG16_parameters.mat', {k.replace('.','_'):v.squeeze().detach().numpy() for k,v in state.items()}) # cant export variable names with . in them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activations to tensor of ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = torch.ones(1, 3, 224, 224).float()\n",
    "one_response = vgg16_places_fe(one)\n",
    "one_response = {key:value.squeeze().detach().numpy() for key,value in one_response.items()}\n",
    "savemat('../matlab analysis/activations_onetensor.mat', one_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activations to tensor of hundrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activations to image 1153"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Check if activation (matlab) and feature extraction (pytorch) return the same values\n",
    "Can check also only correlations, which would include checking the image transformations. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# old code, maybe need this later for investigating why it produces such different activations \n",
    "#im = torchvision.io.read_image('./data/stimuli_places1/Places365_val_00001153.jpg')\n",
    "#im = torchvision.transforms.Resize(size=(224,224))(im)\n",
    "#im = im.unsqueeze(0)\n",
    "#im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import resized img1153 from matlab\n",
    "img = torch.tensor(loadmat('./stimuli_places1_resized/Places365_val_00001153.mat')['im'])\n",
    "img = img.permute((2, 0, 1))\n",
    "img = img.unsqueeze(0)\n",
    "img = img.float()\n",
    "img = img.flip(1)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_act = vgg16_places_fe(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "savemat('../matlab analysis/py_activations1153.mat', {key:value.squeeze().detach().numpy() for key,value in img_act.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually calculate activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = img[:,:,1:3+1,1:3+1].squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = vgg16_places_fe.state_dict()['conv1_1.weight'][0,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3468,  0.3786, -0.0225],\n",
       "         [ 0.2262,  0.0798, -0.2800],\n",
       "         [-0.1114, -0.2863, -0.3753]],\n",
       "\n",
       "        [[ 0.3899,  0.4098, -0.0200],\n",
       "         [ 0.2631,  0.1020, -0.2826],\n",
       "         [-0.0947, -0.2817, -0.3859]],\n",
       "\n",
       "        [[ 0.3372,  0.3692, -0.0315],\n",
       "         [ 0.2289,  0.0854, -0.2699],\n",
       "         [-0.1009, -0.2671, -0.3517]]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.flip(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions (without feature extractor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions for img1153"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 365])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = vgg16_places(img.flip(0))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.8667e-01, 5.8050e-02, 5.1110e-02, 3.2630e-02, 1.1390e-02, 7.1900e-03,\n",
       "         6.2200e-03, 5.8000e-03, 4.5800e-03, 4.2300e-03, 3.9500e-03, 3.6400e-03,\n",
       "         3.5400e-03, 2.1400e-03, 1.8700e-03, 1.8600e-03, 1.3100e-03, 1.1500e-03,\n",
       "         1.1000e-03, 8.3000e-04, 8.0000e-04, 6.7000e-04, 6.3000e-04, 6.1000e-04,\n",
       "         5.0000e-04, 5.0000e-04, 4.1000e-04, 3.8000e-04, 3.8000e-04, 3.4000e-04,\n",
       "         3.1000e-04, 3.1000e-04, 3.1000e-04, 3.0000e-04, 2.7000e-04, 2.2000e-04,\n",
       "         2.2000e-04, 2.1000e-04, 1.8000e-04, 1.6000e-04, 1.5000e-04, 1.4000e-04,\n",
       "         1.1000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 9.0000e-05,\n",
       "         8.0000e-05, 8.0000e-05, 8.0000e-05, 7.0000e-05, 7.0000e-05, 6.0000e-05,\n",
       "         6.0000e-05, 5.0000e-05, 5.0000e-05, 4.0000e-05, 4.0000e-05, 3.0000e-05,\n",
       "         3.0000e-05, 3.0000e-05, 3.0000e-05, 3.0000e-05, 3.0000e-05, 3.0000e-05,\n",
       "         3.0000e-05, 3.0000e-05, 3.0000e-05, 3.0000e-05, 3.0000e-05, 2.0000e-05,\n",
       "         2.0000e-05, 2.0000e-05, 2.0000e-05, 2.0000e-05, 2.0000e-05, 2.0000e-05,\n",
       "         2.0000e-05, 2.0000e-05, 2.0000e-05, 2.0000e-05, 2.0000e-05, 2.0000e-05,\n",
       "         2.0000e-05, 2.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05,\n",
       "         1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05,\n",
       "         1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05,\n",
       "         1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05,\n",
       "         1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05,\n",
       "         1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05,\n",
       "         1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05,\n",
       "         1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05,\n",
       "         1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05,\n",
       "         1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
       "       grad_fn=<RoundBackward1>)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted, indices = torch.sort(output, descending=True)\n",
    "torch.round(sorted, decimals=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[355, 324, 110, 288, 154, 279, 167, 357, 180, 113, 205, 271, 356, 243,\n",
       "          94,  97, 277, 150,  81,   9, 232,  62, 342, 145, 344,  78, 323, 204,\n",
       "         224, 353, 197,  48, 151, 265, 187, 229,  36,   7,  79,  73, 111, 350,\n",
       "         164, 266, 254, 186, 218, 325, 190, 141, 303, 214, 171, 137, 163,  10,\n",
       "         326, 338, 152, 306, 194, 362, 307,  57, 249, 234, 153, 258, 233, 125,\n",
       "         340, 122, 291,  30, 209,  85,  66, 195,  69, 354, 292,  96,  58,  50,\n",
       "         247,  76, 334, 245, 117,  84, 347,  95, 116, 339,  59, 191, 251, 127,\n",
       "         289, 270, 131, 294,  86, 330, 364, 220,   5,  21, 259,   8, 348, 309,\n",
       "         310, 142,  53, 345, 358, 236, 360, 140, 193, 276, 305, 206,  68, 160,\n",
       "         359, 308,  39, 268,  31,  56, 159,  83, 287,  43, 181, 252,  12, 278,\n",
       "          45, 126, 261, 184,  13, 175,  88, 317, 215, 275, 297, 333,  63, 179,\n",
       "          77, 104, 149, 349,  34,  16, 255,  35, 346,  49, 173,  23, 260, 106,\n",
       "          52, 257,  19, 136, 295, 319, 273,   4, 322,  80, 302, 253, 196, 314,\n",
       "         162, 217, 112, 274,  60, 341, 311,  24,  82, 351, 226, 146, 230, 165,\n",
       "          38, 135, 118,  42, 189, 313, 103,  91,  28, 192,  41,  14, 182, 188,\n",
       "         105, 166,  67,  51,  89, 315, 300,  17,  74, 199, 203,  20, 109, 312,\n",
       "         147, 299, 222, 108,  72,  27, 172,  64,   6, 169, 133, 284, 212, 143,\n",
       "           2, 202, 144, 168, 248, 361, 298,  25, 178, 335, 272, 283, 128, 138,\n",
       "         304, 321, 239, 256, 237, 285,  29, 213, 198, 238, 156, 343, 115, 223,\n",
       "         281,  46,  32, 293,  54,  26, 207,  70, 269,  99, 124, 320, 352, 225,\n",
       "         130, 148, 208, 158, 331, 241, 120,  22, 227, 219, 282, 242, 240, 102,\n",
       "         174, 201, 176, 328, 318, 121,  47,   0, 231, 132, 301, 185,  40, 250,\n",
       "           1,   3, 286, 264,  65,  71,  90, 337,  87, 244,  44, 200, 221, 263,\n",
       "          18,  75, 100, 161, 246,  11, 280,  55, 157, 155,  93, 123, 262, 114,\n",
       "         363, 107, 235,  61,  92, 316, 119, 290, 329, 296,  98,  15, 183, 134,\n",
       "         332, 336, 129, 139, 211, 101,  37, 210,  33, 177, 327, 216, 267, 228,\n",
       "         170]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PytorchEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
